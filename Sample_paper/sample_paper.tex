% This is a sample document using the University of Minnesota, Morris, Computer Science
% Senior Seminar modification of the ACM sig-alternate style. Much of this content is taken
% directly from the ACM sample document illustrating the use of the sig-alternate class. Certain
% parts that we never use have been removed to simplify the example, and a few additional
% components have been added.

% See https://github.com/UMM-CSci/Senior_seminar_templates for more info and to make
% suggestions and corrections.

\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorinlistoftodos]{todonotes}

%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR AS NEEDED
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2015}{Morris, MN}

\title{An Examination of Concurrent Compaction Techniques in JVM Garbage Collection}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Jacob P. Opdahl\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{opdah023@morris.umn.edu}
}

\maketitle
\begin{abstract}
This paper provides an overview of garbage collection (GC) of memory and parallel
processing as well as how parallel processing applies to GC; particularly, these
concepts are focused on within the context of the Java Virtual Machine (JVM).
With that knowledge as our foundation, we will examine in detail various
algorithms that perform compaction of fragmented memory during garbage 
collection concurrently to the application running.
% The current paper format *only* allows inline comments using the todo
% macro. That's kind of a bummer, and it would be neat if someone figured
% out how to change the acmconf style to allow this. I suspect it isn't *hard*
% but there are quite a few details that have to be sorted out in synchrony.
\todo[inline]{Needs more work}
\end{abstract}

\keywords{Garbage Collection, GC, Concurrency, Compaction, Continuously Concurrent Compacting Collector (C4), Collie, Field Pinning Protocol (FPP)}

\section{Introduction}
\label{sec:introduction}

To be done at a later date...


\section{Background}
\label{sec:background}

\todo[inline]{Just threw stuff from outline in this section for now.}

This is where I explain terminology and aspects of GC and parallel 
computing that are necessary to understand my paper (If there is 
enough information in each subsection, I should maybe forego the 
background and just make them all sections)

\subsection{Garbage Collection}
\label{sec:garbageCollection}

References and the heap (if not done in the introduction)

General process flow GC algorithms tend to follow

Specific GC algorithms/techniques my researched papers will 
refer to and common techniques needed to understand my paper 
(Pauseless, tracing/marking, more)

Start introducing some terminology relevant to single processor 
garbage collectors such as: stop-the-world, fragmentation, compaction, 
tracing, reference remapping, etc.

Explain the three typical aspects of compaction 
(relocation/copying, remapping, and reclamation: 
reclamation is often just done through the other two)

\subsection{Parallel Processing}
\label{sec:parallelProcessing}

Threads: the virtual form of a processor (might need to 
explain virtualization or abstraction)

Issues experienced in parallel computing and reasons why it 
is difficult to perform effectively like: deadlock, race conditions, 
etc. (Real brief, but I feel the audience needs to have some idea of 
why progress in this area doesn't happen overnight. It also seems 
necessary for explaining barriers)

Typical ways of mitigating challenges experienced in parallel 
computing (synchronization, barriers/locks)

\todo[inline]{Decided a portion I wrote for my current section, Collie,
should be included in the general background. Throwing what I wrote here
for now. Will be rewritten later.}
A \emph{global safepoint} is requested by a thread and is a moment when all 
threads are paused such that operations can be performed by the requesting thread without having to worry 
about references in the application changing. As a global safepoint requires pausing application
threads, this breaks concurrency.
Note that a safepoint differs from a barrier in GC. In a safepoint,
all threads are allowed to reach a certain point then their execution is simply paused.
A barrier works by telling threads how to behave if multiple try to access the same
memory. Thus, using a global safepoint does not break the goal of barrier-free compaction
~\cite{Humble:2015}.

Also, talk about checkpoints here.

\subsection{Parallel Processing as it Applies to Garbage Collection}
\label{sec:parallelProcessingGarbageCollection}

Bring audience's attention back to the original focus introduced 
of wanting to use parallel computing to improve GC

Introduce new terminology for GC that depends on parallel processing 
in order to show some more specific ways in which parallel processing 
can be used to improve GC (mutator threads, parallelism, concurrency, etc.)

Explain Latency vs throughput

Describe the focus: Concurrent Compaction (If this has enough information, 
it could be moved out of being a component in a subsection)


\section{The C4 Collector}
\label{sec:c4}

To be done at a later date...


\section{The Collie Collector}
\label{sec:collie}

We now look at the concurrent compaction technique used within the 
Collie garbage collector described by Iynegar et al.~\cite{Iyengar:Collie}. 
Like C4, the Collie is a fully concurrent compacting collector.
The intended use of the garbage collector is, once again, to
be used on servers with multiple GB heaps and multiple GB/sec allocation rates. 
It uses a tracing algorithm based on the one implemented in C4 for 
marking which objects are garbage. Likewise, the Collie uses a read
barrier similar to the Loaded Value Barrier (LVB) in C4 for 
compaction~\cite{Tene:C4}.


\subsection{Transactional Memory}
\label{sec:collieTM}
The Collie's compaction algorithm sets itself apart due to its use 
of a \emph{transactional memory} (TM) system as a concurrency control 
alternative to barriers~\cite{Iyengar:Collie}. TM systems allow
sections of code to function 
analogously to \emph{transactions} from database systems, 
which are a series of operations performed as one unit where 
they occur in an all-or-none manner~\cite{wiki:atomicity}.

For example, consider updating the inventory of a store; this may involve updating
the price, quantity and distributor for various items. 
If a person was updating information regarding an item, they would 
want all three attributes of the item to be updated or none at all. Having
only a subset of the attributes updated could cause confusion.

TM systems allow a series
of operations that modify memory to be placed in
a \emph{transactional procedure}, much like a database transaction.
The TM system then monitors the access of concurrent threads to \emph{transactional variables}:
memory that is modified by a transactional procedure.
Concurrent threads will continue to operate in parallel until they try to modify
the same transactional variable. At this time, behavior can be specified as to how 
the conflict should play out, but the general pattern would be for one transaction
to be aborted and the other allowed to play out.
When a transaction is completed, its changes are \emph{committed}; any changes 
made to memory by the transaction are finalized~\cite{wiki:transactional-memory}.


\subsection{Object Transplantation}
\label{sec:collieTransplantation}
%I'll probably want to change this subsection title.

% Two possible changes to come here. If C4 also does reclamation the "easy way"
% as described by FPP, then mentioning it in background and elsewhere can probably
% be simplified to a simple note of that being how it's handled by all the algorithms
% I discuss. Also, Might not need the refresher on relocation and remapping if talked
% about recently before.
With the use of a TM system for synchronizing concurrent compaction,
new terminology is introduced for understanding the Collie 
compactor~\cite{Iyengar:Collie}. As discussed, compaction of
memory requires relocation of objects and remapping of references to
the objects; the Collie does reclamation by labeling the from-space as freed.
An object \emph{transplantation} consists of both the relocation and 
remapping of an object. A transplantation has not been completed until
the object's contents have been moved and all required references have been
updated. All relocating collectors, and by extension all
compacting collectors, transplant objects. The Collie compactor attempts to 
perform individual object transplantations within transactional procedures. 

Each object in an application's memory has a \emph{referrer set}. This is the precise set 
of all references pointing to the object. It is crucial that an object's referrer set not
be modified or expanded during the object's transplantation. Doing so could result
in references to the object being created that the transactional procedure
was not aware of when starting, so they are not updated to point to 
the new object location when it is finishing. To avoid this, a referrer set can be
\emph{protected} by writing to each reference within it and preventing it from
being read temporarily.

There is also a notion of a \emph{stable} referrer set. An object has a stable referrer 
set if the object's referrer set meets the following criteria:
\begin{enumerate}
\item Once the overall GC process begins, no references to the object may be written to the heap
\item At the start of the object's transplantation, no threads contain references to the object in their stacks/registers
\item Once transplantation is underway, no new references may be added to the object's transplantation state until it is complete
\end{enumerate}
This ensures the compactor is aware of all reference to the object
and the references to the object go unchanged.

An object has a \emph{transplantation state} consisting of the object's contents 
and the object's referrer set. This definition builds on the general requirements
for completing an object transplantation. These
requirements include: all copies of an object's contents should remain consistent
until transplantation is completed and after transplantation, there cannot be any
references that point to the object's from-space location in its referrer set.

\todo[inline]{Might need to add more background. Wait to see how discussing the algorithm goes. Add: mirrored to-space, zero-copy translation.}

\subsection{The Collie Protocol}
\label{sec:collieAlgorithm}

While working to use a TM system to support concurrent thread 
synchronization, the first theoretical, 
but not practical, barrier-free compacting algorithm is 
conceived~\cite{Iyengar:Collie}. From this,
a wait-free read barrier as well as
the concepts of a \emph{mirrored-to-space} and 
\emph{zero-copy transplantation} are introduced into the algorithm.
This is done to make the compaction algorithm practical and concurrent
so it can be used in the overall Collie GC algorithm.
We will discuss both the theoretical compaction algorithm as well
as the modified concurrent implementation here.

\subsubsection{Theoretical, Barrier-free Compaction Algorithm}
\label{sec:collieAlgorithmNoBarriers}

The compaction algorithm uses TM semantics to complete an object's
transplantation~\cite{Iyengar:Collie}. The operations for transplantation are stored as a
transactional procedure. These operations include: the compactor 
starting a memory transaction, it protecting the referrer set, 
the object being copied to its new location and the references in the 
referrer set being updated to point to the new location of the object.
After the final steps modifying the transplantation state of the object,
the transaction is committed.

If the aforementioned transactional procedure is not
modified, there will be a gap between the transaction beginning and
the entire referrer set being written to and protected. This gap allows 
the referrer set to expand without the transaction knowing about it
as discussed.

To prevent this, the transactional procedure must be started inside a global safepoint.
Within the global safepoint, the precise referrer
set is constructed, the transaction is started, and the referrer set is protected.
After this, the safepoint ends and other threads are allowed to continue concurrently
while TM semantics will ensure the actual individual object transplantation portion
of compaction is safe.

This brings us to why this compaction algorithm is not concurrent. 
While it does not require traditional barriers, the safepoint solution to
controlling the referrer set
requires stop-the-world phases. These global safepoints would need to be enacted for every 
object that is relocated. Thus, the number of stop-the-world pauses that would occur
during this barrier-free compaction algorithm make it impractical.

% Might want a summary with a final figure of the pseudo-code for the algorithm.

%Do you feel I need to explicitly state what would cause the transactional
%memory to kick in and handle concurrency issues? I think I covered it enough with the
%additional background.
%Talk more about operations that would cause the transaction to be aborted and give examples?


\subsubsection{Aborting Compactor}
\label{sec:collieAbortion}

The compactor in the Collie GC algorithm uses barriers 
and transactions that will abort the transplantation process of an object if the
GC threads and mutator threads conflict to maintain concurrency~\cite{Iyengar:Collie}.
However, objects that have their transplantation aborted would then be stuck
in from-space, which would mean compaction is never performed. This is where
the additions of a mirrored-to-space and zero-copy transplantation come into play.

Mirrored-to-space is a virtual address space that corresponds to and is the same
size as from-space. Mirrored-to-space memory pages are mapped to the same physical
memory as their corresponding from-space pages are. For barrier test and compaction 
termination purposes, mirrored-to-space is logically considered part of to-space.

Mirrored-to-space is necessary to facilitate zero-copy transplantation that is 
non-compacting between from-space and to-space. Since an object's contents are 
already consistent between from-space and mirrored-to-space and mirrored-to-space
is logically considered to be to-space, transplantation to "to-space"
can be done without copying the object's contents. That is, zero-copy transplantation
allows transplantation of an object from from-space to mirrored-to-space, which only
requires correcting references.

Ideally, the compaction algorithm will never have to use zero-copy transplantation
as it does not actually compact the heap. The purpose of this is to ensure
objects make it to "to-space" should their transplantations need to be aborted. 
This allow mutators to continue working while also guaranteeing the compaction 
process can terminate.


\subsubsection{Implemented Compaction Algorithm}
\label{sec:collieAlgorithmImplementation}

After a tracing phase at the start of the overall GC algorithm, the compaction of
the heap happens during the \emph{transplantation phase}~\cite{Iyengar:Collie}.
At this time, it is known which objects are relocatable; that is, the compactor knows which 
objects are not trash. Individual object transplantation will be done on relocatable objects 
that successfully maintain stable referrer sets throughout the process.

An object is deemed \emph{non-individually transplantable} (NIT) if its transplantation
has to be aborted or if it fails to maintain a stable referrer set. 
Any object that is deemed as such will be moved to mirrored-to-space by zero-copy 
transplantation. An object may be declared NIT during the tracing phase before transplantation
if it violates requirement 1 for having a stable referrer set; discussion of details
of how this occurs is orthogonal to the purposes of this paper.

At the start of the transplantation phase, a pre-compaction checkpoint occurs.
For all the relocatable objects, referrer sets have been established during the tracing phase.
These referrer sets need to be stable referrer sets. As such, the objects are checked for 
references to them in threads' stacks and registers. Any objects with these will be 
marked NIT as their referrer sets fail to meet requirement 2 for being a stable referrer set.
After the checkpoint, the compactor has a set of relocatable objects with currently stable referrer sets.

The pre-compaction checkpoint also kicks off the LVB-style read barrier's first purpose. 
The barrier will trigger on the load of a reference to an object that was 
relocatable. Upon being triggered, the object will be marked NIT. This is done because
the load operation adds another reference to the object's referrer set, which violates
requirement 3 of having a stable referrer set.

With the set of objects to be transplanted, the compactor uses transactional
procedures to complete the individual object transplantations to to-space.
The copying of an object can actually occur outside the transaction since any
mutator access of the object will lead to triggering the LVB-style read barrier,
which will render the object NIT. Thus, only the work of updating the referrer set
is done in the transactional procedure. The transaction looks like:
\begin{enumerate}
\item Transaction is started
\item References are checked to make sure none point to the mirrored-to-space location as this means the object had been changed to NIT by some previous, interrupting operation
\item All references are changed to point from an object's from-space location to its new to-space location
\item Memory transaction is committed
\end{enumerate}
If a transaction fails or is interrupted, as detected by the TM system, then the object is rendered NIT.

After the transactional procedure either succeeds or fails for all of the objects that were
relocatable with stable referrer sets, all that is left to do perform zero-copy transplantation
on all NIT objects. To avoid an extra traversal of memory, this can be rolled into the next tracing
phase, much like C4 does~\cite{Tene:C4}. The second purpose of the LVB-like barriercomes into play
at this time. If a mutator thread attempts to access a NIT object before its accessing 
reference is updated to mirrored-to-space, the barrier will prevent the thread and cause the mutator to 
correct the reference.

\subsection{Summary of Results}
\label{sec:collieResults}
%Again, another name for this subsection could be good.

Since the Collie uses a compactor that aborts on mutator interference to allow
 concurrency, there are no copy-progress guarantees for the algorithm~\cite{Osterlund:FPP}.
While extremely unlikely, this means a GC cycle could be performed without compacting
any portion of the heap. Since the Collie reclaims memory by labeling the from-space as freed,
this would mean no garbage is actually collected should this occur.

The referrer sets built during the GC process are done per object. Keeping track of them
will require extra space overhead. The amount of overhead this would cause is discussed in
general terms, but no numbers are provided. It is noted that the overall space needed will 
depend upon the specific storage mechanisms used, but these mechanisms are not 
investigated~\cite{Iyengar:Collie}. However, allowing referrer set to take
more space is shown to result in more memory being reclaimed.

Like the C4 garbage collector, the Collie collector is tested against a modified
variant of the Pauseless collector~\cite{Iyengar:Collie}. Accordingly, it is 
implemented on the same JVM that Pauseless runs on~\cite{Click:Pauseless}. For the 
hardware specifications, refer to~\cite{Iyengar:Collie}. The goal of the Collie 
collector to reduce latency compared to the Pauseless collector was achieved. 
It also managed to increase throughput as a side-effect. 

%Find out what I should do for these and get figures as needed.


\section{Field Pinning Protocol}
\label{sec:fpp}

To be done at a later date...


\section{Conclusions}
\label{sec:conclusions}

To be done at a later date...


\section*{Acknowledgments}
\label{sec:acknowledgments}

To be done at a later date...


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% sample_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{sample_paper}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\end{document}

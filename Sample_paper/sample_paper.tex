% This is a sample document using the University of Minnesota, Morris, Computer Science
% Senior Seminar modification of the ACM sig-alternate style. Much of this content is taken
% directly from the ACM sample document illustrating the use of the sig-alternate class. Certain
% parts that we never use have been removed to simplify the example, and a few additional
% components have been added.

% See https://github.com/UMM-CSci/Senior_seminar_templates for more info and to make
% suggestions and corrections.

\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorinlistoftodos]{todonotes}

%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR AS NEEDED
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2015}{Morris, MN}

\title{Concurrent Compaction in JVM Garbage Collection}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Jacob P. Opdahl\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{opdah023@morris.umn.edu}
}

\maketitle
\begin{abstract}
This paper provides an overview of garbage collection (GC) of memory 
in programming languages and parallel processing as well as how 
parallel processing applies to GC; particularly, these
concepts are focused within the context of the Java Virtual Machine (JVM).
We examine in detail various algorithms that perform compaction of fragmented 
memory during garbage collection concurrently to the application running.
The desire for such GC behavior stems from a desire to reduce stop-the-world
pauses of an application.
% The current paper format *only* allows inline comments using the todo
% macro. That's kind of a bummer, and it would be neat if someone figured
% out how to change the acmconf style to allow this. I suspect it isn't *hard*
% but there are quite a few details that have to be sorted out in synchrony.
\end{abstract}

\keywords{Garbage Collection (GC), Concurrency, Compaction, Continuously Concurrent Compacting Collector (C4), Collie, Field Pinning Protocol (FPP)}


\section{Introduction}
\label{sec:introduction}

In object-oriented programming languages, the allocation and deallocation
of memory for objects can be explicit or implicit. If done implicitly,
a language is said to have \emph{automatic memory management}. Some languages 
with automatic memory management are C\#, Java, and Python.
Use of automatic memory management is beneficial to programmers as it provides
the robustness of an object-oriented language without worrying about
details unrelated to what the program is intended to do; specifically, users do
not have to worry about the details of memory allocation and deallocation. 
However, programmers also do not have control over how memory management occurs,
which can have negative impacts on application performance.

Memory for a program is not an unlimited resource. As such, automatic memory management
must ensure objects that are no longer needed are removed from memory
when appropriate. Dead objects, or \emph{garbage}, are objects that can be shown
to be unreachable by the program~\cite{glossary:g}. Thus, garbage should be deallocated to 
save space for new objects that will be created. The algorithm used to perform implicit
deallocation of garbage is referred to as a \emph{garbage collector}.
A garbage collector is a sophisticated algorithm designed to detect
and remove dead objects. We will focus on specific parts of the 
garbage collection (GC) process performed on Java Virtual Machines 
(JVMs), software processes that run Java programs on computing systems~\cite{Lindblom:2011}.

GC is not without cost.
Just like the application, GC requires processing resources to run. After all,
a GC algorithm is another piece of software. When using a single processor, 
we get a \emph{serial} garbage collector operating in a 
\emph{stop-the-world} fashion~\cite{Lindblom:2011}; GC requires
pausing the application in order to clean. With storage media growing, 
applications are experiencing a growth in memory
available to them. Likewise, garbage collectors are performing more
work as there is more garbage to remove. Thus, the stop-the-world
pauses applications experience are growing larger.

% If this isn't good, maybe refer back to Jeff's paper to show how 
% many serial garbage collectors are hitting walls.
Clearly, stop-the-world behaviors are not desirable. In some environments,
application pauses are unacceptable. In order to decrease or remove these 
pauses, we want to use \emph{parallel processing}. With the growing
need for faster responding applications coupled with greater amounts of memory needing managing,
it is paramount that GC be optimized using parallel processing. Languages with
automatic memory management need this in order to remain useful today,
and it would be a waste not to make use of the additional processing power
many machines have available today.

In Section 2, we cover more of what GC entails. Then, we go over the
basic concepts of parallel processing of programs. We combine this 
to discuss how parallel processing is used for GC.
From there, we focus our examination of parallel processing in GC in Sections 3, 4, and 5;
we examine how a specific component of GC can be made to run parallel to
and independent of the application running. To this end, we cover three
different techniques that are all implemented and tested within different
garbage collectors.


\section{Background}
\label{sec:background}


\subsection{Garbage Collection (GC)}
\label{sec:garbageCollection}

Newly allocated objects in JVM languages are stored in a contiguous memory location referred
to as the \emph{heap}~\cite{oracle:heap}. The heap represents the memory available to a program.
Thus, when GC removes garbage, it cleans the heap.
An application accesses objects stored on the heap through \emph{references},
fixed-size values that refer to object locations in the heap~\cite{reilly:reference}. 
As such, an application process never stores
an actual object. It stores references to objects in a memory structure known
as the \emph{stack}, which is separate from the heap.
The heap is a virtual layer of memory that corresponds to physical memory.
References pointing to object locations actually point to their
virtual locations rather than their physical locations. Objects may also 
contain references to other objects, so references may appear on the heap.

In GC, the overarching pattern common to all algorithms is determining garbage
and reclaiming memory from dead objects~\cite{wiki:gc}. This can be broken down into two major steps.
First, a GC algorithm performs \emph{set condemnation} when deciding which objects are 
garbage. The garbage collectors we examine perform set condemnation using a method 
known as \emph{tracing}. During this, objects are determined to be reachable by 
traversing references from global, root objects. Any objects reachable by chaining references
from these global, root objects could still be used by the application. 
Any objects not reachable are garbage. Then, the algorithm performs 
\emph{reclamation} by recovering the memory held by garbage objects. A full
performance of the overall GC pattern is known as a \emph{cycle}, and it
is usually started when the heap is full.

To optimize GC, a variant can be performed known as \emph{generational} GC.
Generational collectors are based on the \emph{weak generational hypothesis}~\cite{Tene:C4}.
This says most objects do not live on the 
heap long. Thus, GC efforts are focused on these objects. Typically, this is achieved
by dividing the heap into two generations. One generation focuses on the younger objects and
is collected more frequently. If objects in the young generation of the heap survive
enough GC cycles, it will move into the old generation. By not considering the entire
heap with each GC cycle, an application experiences less disruptions.

As memory is reclaimed by a garbage collector, the heap is subject to 
\emph{fragmentation}~\cite{Tene:C4}~\cite{Iyengar:Collie}~\cite{Osterlund:FPP}. Fragmentation is the forming
of interspersed locations of used space in contiguous memory. This
is an issue as space for new objects being allocated
on the heap becomes difficult to find and manage. 

For example. Assume
we have an object that takes 4MB of memory. After several cycles of GC,
we have gaps of open memory with a size of at most 2MB contiguously. Thus, 
the JVM experiences additional overhead in allocating space for this object
as it has to store parts of it across non-contiguous locations. Additionally,
more overhead will be experienced as accessing the object will require locating
all of its parts.

This is where \emph{compaction} becomes relevant. Compaction fights
fragmentation of the heap by moving lives objects into contiguous memory locations.
Compaction is performed by a garbage collector and is part of GC. Two steps
are typically involved in compaction. \emph{Relocation} occurs by moving live objects
to a contiguous memory location after set condemnation.
The contiguous memory location being moved to is often referred to as \emph{to-space}.
The location an object is moved from is referred to as \emph{from-space}. While it is called 
relocation, objects are typically copied rather than moved. \emph{Remapping}
occurs after objects have been relocated; the remapping phase 
updates all references to moved objects to refer to their new locations. Often, reclamation
in compacting collectors is performed by marking from-spaces as freed.


\subsection{Parallel Processing Basics}
\label{sec:parallelProcessing}

To develop an understanding of parallel processing, we need to know 
what \emph{processes} and \emph{threads} are~\cite{oracle:threads}.
A process is an instance of a computer program being run. What we
see as an application being run can actually incorporate multiple processes.
For example, a Java application being run and GC being performed on the application are two processes.
A thread, at a basic level, is a component of a process. A thread performs a sequence
of instructions that are part of a process the thread belongs to. In JVM languages,
each thread has a personal stack to keep track of variables
and references used within its specific set of tasks. A process
can involve a single thread or multiple threads.
Parallel processing is the utilization of multiple
cores of a CPU to run threads concurrently. If processes are set up
to run with multiple threads, the extra processing power can be used to make 
the process more efficient.

% Could make an image for this example if needed and space allows.
% HOnestly, this whole paragraph could possibly be removed too...
%If I do, remove the last sentence of the preceding paragraph too.
If parallel processing makes running processes more efficient, why is it not
always used? The reason is creating parallel processes subjects
developers to new challenges. Many new issues can result from use of
multi-threading. One example, relevant to GC, is modifications to an 
object can be lost. For example, say there is an application keeping 
track of people's moods and locations. People are stored as objects. 
Thread 'a' moves people, and it does so by relocating them in data structures (DSs) 
with a deep copy and delete operation. Thread 'b' updates people's moods. Suppose a person
is about to go home from work, so their mood changes to happy.
The person's change in mood could be lost if thread 'a' copies the person
to the home DS, thread 'b' updates the person's mood while still expecting
them to be in the work DS, and thread 'a' deletes the person from the work DS. 
While the example is fairly simple, it can be seen how this type of problem
applies to GC.

To deal with multiple threads relying on use of the same data, \emph{synchronization}
techniques are used. These ensure threads do not interfere
with one another in a process-breaking manner. A \emph{memory barrier} (referred to 
as a read barrier or simply barrier) is an instruction set enforced upon the 
CPU to be performed before accessing memory~\cite{wiki:barrier}. Uses of this include ensuring threads
meet certain requirements before accessing memory or disallowing a thread to
access memory while another thread is using the memory.
 
A \emph{checkpoint} is a technique
where all threads are required to pass through a barrier-like function at some point
during an overall process~\cite{Tene:C4}. Going back to our moods and locations example, say we
now have multiple threads in charge of relocating people. These threads
could be required to store a flag on their stacks when relocating a person.
When thread 'b' tries updating someone's mood, all threads go through
a barrier function checking if there is a flag for relocating that person. This
could prevent thread 'b' from updating a person's mood while they are being relocated.


\subsection{GC with Parallel Processing}
\label{sec:parallelProcessingGarbageCollection}

We can now return to our original goal of applying parallel processing to GC.
Threads that are part of the application process are referred to as \emph{mutator}
threads (or mutators) because they mutate the data~\cite{Tene:C4}~\cite{Iyengar:Collie}
\cite{Osterlund:FPP}. Threads used by the garbage collector are simply GC threads.

A \emph{parallel} garbage collector is one using
multiple threads simultaneously to complete its GC process.~\cite{Puffitsch:background}
All but one of the garbage collectors we examine are parallel. A \emph{concurrent} garbage
collector is one executing in parallel to the application running. In other 
words, the garbage collector does not entirely stop-the-world. A GC algorithm
could be only partially concurrent or parallel. For example, one collector may
only have the tracing phase be parallel while reclamation is concurrent.

We focus on three techniques for performing
concurrent compaction within GC. We do so due to the importance 
of having non-stop-the-world garbage collectors. Additionally, compacting
collectors are vital when trying to optimize application performance. Thus,
the intersection of these two optimizations to languages with automatic memory management leads
to researching ways to perform concurrent compaction within GC.

All compaction techniques we examine are used in garbage
collectors for testing purposes. One important metric used to consider
how a collector is affecting an application is \emph{latency}~\cite{Lindblom:2011}.
Within GC, latency is a measure how much a collector negatively impacts
application processing performance. A higher latency implies the collector
is taking up more processing resources that the application could be using. It 
can be measured in various ways and is usually collected in the same manner
among multiple collectors for comparative purposes.


\section{The C4 Collector}
\label{sec:c4}

\todo[inline]{Things that have changed since 4 page draft: results}

%I think I got enough introductory info describing the context of C4
%here. Might want to check with Elena.
The first concurrent compaction algorithm we examine is implemented in the 
Continuously Concurrent Compacting Collector (C4), which is a garbage collector 
included in JVMs commercially shipped by Azul Systems~\cite{Tene:C4}. The 
researchers, Iyengar et al., describe how C4 is an enhanced, generational variant
of the Pauseless garbage collector~\cite{Click:Pauseless}. C4 is generational in 
that the entire GC algorithm is independently utilized in both the young and old generations 
concurrently; in addition, both generations have garbage collected concurrently 
to the application running. For set condemnation, C4 uses a tracing-style algorithm.
C4 is intended to be used in server environments with multiple GB heaps and 
multiple GB/sec allocation rates.


\subsection{Loaded Value Barrier}
\label{sec:c4LVB}

C4 uses a barrier referred to as the \emph{Loaded Value Barrier} (LVB) to 
maintain concurrency throughout the GC process~\cite{Tene:C4}. The LVB 
places invariants on each object reference value as it is loaded from memory.
One of the invariants relates to the tracing portion of the GC algorithm, so
it is not discussed here. The other invariant ensures
references to an object being relocated must point 
to wherever the object can be safely accessed, be it the from or to-space.
If the invariant does not hold
when a reference is loaded, the barrier will trigger and execute code to correct
the situation. The code executed is discussed later.

In order to prevent repetitive barrier triggers from a single incorrect reference,
the LVB uses a \emph{self-healing} technique. Whenever a reference triggers LVB
due to not meeting an invariant, it will perform the rectifying code
necessary to fix the reference. Additionally, the barrier will go to the memory
location the reference was loaded from and fix the source of the reference. This
ensures not only the loaded reference being used is fixed, but the stored reference
that might be loaded again later is also fixed.
Thus, self-healing helps reduce the occurrence of the read barrier triggers.


\subsection{Concurrent Relocation}
\label{sec:c4Relocation}

The relocation aspect of compaction in C4 occurs on a per-\emph{page}
basis, where a page is a fixed-length, contiguous block of virtual memory in the heap
that is backed by a contiguous block of physical storage~\cite{wiki:page}\cite{Tene:C4}.
To quickly empty virtual pages, the most sparsely populated pages are relocated
first. The from-space in this relocation is actually from-pages, and the to-space
is to-pages. From-pages are pages with garbage
and are marked as such during the tracing phase.

To support concurrent relocation, pages being relocated are protected. 
The LVB will trigger for mutator threads encountering a reference to an object
on a protected page. If the object has been relocated already, LVB will
obtain the new location for the mutator. If the object is being relocated, 
LVB will cause the mutator to wait
for the GC thread to finish before continuing to work.
If the object has not started relocation, LVB has the mutator thread 
escalate its movement status by moving the object itself. After any of 
these situations, the LVB will also cause the mutator thread to update 
the reference to the new location and heal the source location of the reference.
Without any mutator interference, GC threads will relocate the objects but
will not remap references at this time. The barrier check and subsequent
handling a mutator thread experiences when attempting to access an object on a
protected page can be seen from the pseudocode below adapted from~\cite{Tene:C4}.
\begin{verbatim}
LVBCheck(referenceAddress, reference)
  trigger = 0;
  // Check for tracing invariant here.
  if (pageIsProtected)
    set trigger = Reloc_Trigger;
  if (trigger != 0)
    reference = LVBHandler(referenceAddress, 
                  reference, trigger);
    
LVBHandler(address, reference, trigger)
  oldReference = reference;
  // Handle tracing trigger if that was the cause.
  if (trigger = Reloc_Trigger) 
    if (objectNotYetRelocated(reference))
      relocateObjectAt(reference);
    reference = lookupNewObjectLocation(reference);
  // Self-Healing
  compareAndSwap(address, oldReference, reference);
  return reference;
\end{verbatim}
When all living objects are relocated from a page marked for relocation,
the C4 compactor will utilize a \emph{Quick Release} method. In order to quickly recycle
physical memory sources, the physical memory backing the page will be freed
as soon as the last live object has been moved to a to page. The objects have already 
been transferred to new pages, so the contents of the from-pages are no longer needed. Thus,
physical memory backing from-pages can be used immediately. The from-page's virtual 
addresses will be in use until all references have been remapped, but this 
allows for efficient recycling of physical memory. This is made possible as the C4 compactor
stores object forwarding information outside of a from-page. Thus, when a reference to
a from-page is loaded, LVB has the mutator check the forwarding table rather than the
from-page to see where an object has moved to.


\subsection{Concurrent Remapping}
\label{sec:c4Remapping}

To maintain concurrency while updating all references to the now relocated
objects, the C4 compaction algorithm uses two techniques~\cite{Tene:C4}. The first is
referred to as \emph{lazy remapping}. With this, mutator
threads continue updating references as they trigger the LVB. In order for
the remapping phase to end, all live references must be updated.
This could go on indefinitely if lazy remapping alone is performed.

To finish remapping, a traversal of live references must be performed to
ensure all are updated; this is like the traversal performed to trace which
objects are garbage. Since no physical resources are being held due
to Quick Release and lazy remapping does not disrupt mutator operations,
the remapping traversal is pushed off until another GC cycle starts. That
is, C4 will have the remapping of one GC cycle be performed while the tracing
of another cycle is beginning. This works as both processes need to traverse
the same references in memory to find all that are reachable. To
visualize how this works, examine Figure~\ref{fig:c4Cycle}. Upon remapping completion, 
all references to from-pages are now gone. Thus, the virtual resource
can be freed and reclamation of memory is now entirely complete. 

\begin{figure}
\centering
\psfig{file=c4Mapping_rough_figure.pdf,width =3in}
\caption{C4 GC cycle. Remapping and Tracing are rolled into one traversal.
(taken from \cite{Tene:C4})}
\label{fig:c4Cycle}
\end{figure}


\subsection{C4 Results Summary}
\label{sec:c4Results}

% Tested primarily against also concurrent, but non-generational.

Experiments done with the implemented C4 algorithm were meant to show improvements
of using an algorithm that is simultaneously generational and concurrent~\cite{Tene:C4}.
C4 is tested against a modified, non-generational C4 algorithm. Additionally,
it is tested against two algorithms that do not perform concurrent compaction. 
All GC algorithms were tested on the same hardware; for specifications, see~\cite{Tene:C4}. 
The test exhibited a workload with
an allocation rate of about 1.2GB/sec and live sets of objects on 
the heap consistently at a size of around 2.5GB; the actual heap size was allowed 
to grow though, indicating greater amounts of garbage on the heap. The applications were run long
enough to ensure multiple full-heap GC cycles ran and at least one
significant compaction event occurred.

The primary performance metric monitored was the worst-case response times
of servers responding to requests while experiencing the workloads
described. While not directly measuring latency, this gives a sense of how 
much latency a garbage collector causes. 
C4 maintained the smallest 
worst-case response times across the largest range of heap sizes.
The worst-case response times were usually in the range of 0.01-0.1secs. 
These response times are fast enough to be considered \emph{pauseless}. 
The non-generational version of C4 could also reach pauseless thresholds,
but the range of heap sizes it could do so for was more limited. Where standard
C4 sustained pauseless operation for heap sizes of 5-35GB, the modified C4 could
only do so for heaps sizes of 15-35GB. The non-concurrently compacting
collectors had multi-second worst-case response times for all heap sizes experienced.


\section{The Collie Collector}
\label{sec:collie}

We now look at the concurrent compaction technique used within the single-threaded
Collie garbage collector described by Iynegar et al.~\cite{Iyengar:Collie};
with the exception of Gehringer, they were the researchers who worked on the C4 algorithm.
As such, Collie utilizes modified versions of several techniques from C4, such as:
the tracing algorithm, the LVB, page-granularity compaction, self-healing, and quick-release behavior.
Only the LVB is modified in significant ways for the purposes of compaction in Collie.
The rest of the techniques are not re-discussed here due to performing 
similarly to their C4 counterparts. Like C4, the Collie
collector is also designed with server environments in mind. 
Collie is implemented and tested in 
the same production-quality Azul JVM the Pauseless garbage collector is implemented in
~\cite{Click:Pauseless}. However, it has not been made commercially available.


\subsection{Transactional Memory}
\label{sec:collieTM}

The Collie's compaction algorithm sets itself apart due to its use 
of a \emph{transactional memory} (TM) system as a concurrency control 
alternative to barriers~\cite{Iyengar:Collie}. TM systems allow
sections of code to function 
analogously to \emph{transactions} from database systems, 
which are a series of operations performed as one unit where 
they occur in an all-or-none manner~\cite{wiki:atomicity}.

For example, consider updating the inventory of a store; this may involve updating
the price, quantity, and distributor for various items. 
If a person updates information regarding an item, they would 
want all or none of the item's attributes to be updated. Having
only a subset of the attributes updated could cause confusion. A transaction
would ensure an item is unchanged if the process of updating the item's info 
is started and then aborted before completion.

TM systems allow a series
of operations modifying memory to be placed in
a \emph{transactional procedure}, much like a database transaction.
The TM system then monitors the access of concurrent threads to \emph{transactional variables},
memory modified by a transactional procedure.
Concurrent threads will operate in parallel until they try to modify
the same transactional variable. At this time, how 
the conflict should resolve can be specified, but the general behavior would be for one transaction
to be aborted and the other allowed to continue.
When a transaction is completed, its changes are \emph{committed}; any changes 
made to memory by the transaction are finalized~\cite{wiki:transactional-memory}.


\subsection{Object Transplantation}
\label{sec:collieTransplantation}

With the use of a TM system for synchronizing concurrent compaction,
new terminology is introduced for understanding the Collie 
compactor~\cite{Iyengar:Collie}. 
An object \emph{transplantation} consists of both the relocation and 
remapping of an object. A transplantation is not complete until
the object's contents have been moved and all required references have been
updated. All relocating collectors, and by extension all
compacting collectors, transplant objects. The Collie's compactor 
performs individual object transplantations within transactional procedures. 
Building on this, an object has a transplantation state consisting of the object's contents 
and the object's referrer set.

Each object in an application's memory has a \emph{referrer set}. This is the precise set 
of all references pointing to the object. It is crucial that an object's referrer set not
be modified or expanded during the object's transplantation. Doing so could result
in references to the object being created that the transactional procedure
was not aware of when starting, so they are not updated to point to 
the new object location when it is finishing. To avoid this, a referrer set can be
\emph{protected} by writing to each reference within it and preventing it from
being loaded temporarily.

There is also a notion of a \emph{stable} referrer set. An object has a stable referrer 
set if the object's referrer set meets the following criteria:
\begin{enumerate}
\item Once the overall GC process begins, no references to the object may be written to the heap
\item At the start of the object's transplantation, no threads contain references to the object in their stacks
\item Once transplantation is underway, no new references may be added to the object's \emph{transplantation state} until it is complete
\end{enumerate}
This ensures the compactor is aware of all references to the object
and references to the object go unchanged.


\subsection{The Collie Protocol}
\label{sec:collieAlgorithm}


\subsubsection{Aborting Compactor}
\label{sec:collieAbortion}

The compactor implemented in the Collie GC algorithm uses barriers 
and transactions that will abort the transplantation process of an object if the
GC threads and mutator threads conflict to maintain concurrency~\cite{Iyengar:Collie}.
However, objects that have their transplantation aborted would then be stuck
in from-space, which would mean compaction is never performed. This is why
the additions of a \emph{mirrored-to-space} and \emph{zero-copy transplantation} are necessary.

% THere's definitely some repition here. Worry about later.
Mirrored-to-space is a virtual address space that corresponds to and is the same
size as from-space. Mirrored-to-space memory pages are mapped to the same physical
memory as their corresponding from-space pages. For barrier test and compaction 
termination purposes, mirrored-to-space is logically considered part of to-space.

Mirrored-to-space is necessary to facilitate non-compacting, zero-copy transplantation 
between from-space and to-space. An object's contents are 
consistent between from-space and mirrored-to-space and mirrored-to-space
is logically considered to be to-space. Thus, transplantation to "to-space"
can be done without copying the object's contents. That is, zero-copy transplantation
allows transplantation of an object from from-space to mirrored-to-space, which only
requires correcting references. The purpose of this is to ensure
an object makes it to "to-space" should its transplantation need 
to be aborted because mutators need to access it.

% Could make a cake example instead if this isn't really helpful.
As an example, consider an object stored in memory. As discussed before, all references
to this object are actually references to its virtual page location. This virtual page
is backed up by some contiguous, physical memory equivalent in size to the page. 
Mirrored-to-space is simply another page that is assigned to the same section of physical memory. 
The only difference between mirrored-to-space and the page our object is stored on
is references to the object used by mutators point to its virtual page.
Zero-copy transplantation swaps this. All references to the object are
updated to point from the virtual page to mirrored-to-space. 
Thus, we get the name \emph{zero-copy} translation
because our object is never moved in physical memory; the object simply
swaps virtual pages for the purposes of the compactor believing all of from-space
has been compacted.


\subsubsection{Compaction Implementation}
\label{sec:collieAlgorithmImplementation}

After a tracing phase at the start of the overall GC algorithm for set condemnation, heap compaction
happens during a \emph{transplantation phase}~\cite{Iyengar:Collie}.
Live, relocatable objects and their referrer sets are known at this time. The compaction 
algorithm uses TM semantics to complete an object's
transplantation. The operations for transplantation are stored as a
transactional procedure. Individual object transplantations will be done on relocatable objects 
maintaining stable referrer sets throughout the process.

An object is deemed \emph{non-individually transplantable} (NIT) if its transplantation
has to be aborted or if it fails to maintain a stable referrer set. 
Any object deemed as such will be moved to mirrored-to-space by zero-copy 
transplantation. An object may be declared NIT during the tracing phase before transplantation
if it violates requirement 1 for having a stable referrer set; discussion
of how this occurs is beyond the scope of this paper, see~\cite{Iyengar:Collie}.

% Talk about this barrier because it is during GC - betweentracing and transplantation.
% If others experience something similar, they should be talked about too.
At the start of the transplantation phase, a pre-compaction checkpoint occurs.
For all relocatable objects, referrer sets have been established during the tracing phase.
These referrer sets need to be stable referrer sets. As such, threads' stacks are checked 
for references to the objects. Any objects with these will be 
marked NIT as their referrer sets fail to meet requirement 2 for being stable referrer sets.
After the checkpoint, the compactor has a set of relocatable objects with currently stable referrer sets.

The pre-compaction checkpoint also kicks off the LVB-style read barrier's first purpose. 
The barrier will trigger on the load of a reference to an object that was 
relocatable. Upon being triggered, the object will be marked NIT. This is done because
the load operation adds another reference to the object's referrer set, which violates
requirement 3 of having a stable referrer set.

With the set of objects to be transplanted, the compactor uses transactional
procedures to complete the individual object transplantations to to-space.
The copying of an object occurs outside the transaction since any
mutator access of the object will trigger the LVB-style read barrier,
rendering the object NIT. Thus, only the referrer set updating
is done in the transactional procedure. The transaction looks like:
\begin{enumerate}
\item Transaction is started
\item References are checked to make sure none point to the mirrored-to-space location as this means the object had been changed to NIT by some previous, interrupting operation
\item All references are changed to point from an object's from-space location to its new to-space location
\item Memory transaction is committed
\end{enumerate}
If a transaction fails or is interrupted, as detected by the TM system, then the object is rendered NIT.

After the transactional procedure either succeeds or fails for the 
relocatable objects with stable referrer sets, all that remains is to perform zero-copy transplantation
on all NIT objects. Just like the C4 compactor, Collie will do this lazily. This is the second purpose
of the LVB-like barrier; as mutators try to access NIT objects before their references are updated to
point to mirrored-to-space, the barrier will force them to correct the references. Also like C4, Collie
rolls the full traversal of memory to finish zero-copy transplantation of all NIT objects into the next
tracing phase.


\subsection{Collie Results Summary}
\label{sec:collieResults}

% Tested primarily against Another concurrent that is also modified to run on a single thread.

The main goal of the Collie collector is to decrease latency
during compaction~\cite{Iyengar:Collie}. The Collie was tested 
against a modified variant of the Pauseless collector~\cite{Click:Pauseless}.
Accordingly, both collectors were implemented on the same JVM. For hardware
specifications used for testing, refer to~\cite{Iyengar:Collie}. The Collie
utilizes several aspects of the C4 collector, which in turn builds upon the Pauseless
collector. This provides an effective comparison to see how the main differences, 
use of transactional memory and an aborting compactor, affect application performance. 

To examine latency, \emph{minimum mutator utilization} (MMU) is measured.
MMU is the minimum percentage of mutators being utilized over a period of time~\cite{Bacon:MMU}. Ideally,
MMU would always be at 100\% so all mutators are being used. 
MMUs were taken from various time periods during which
compaction was running and was compared between the two algorithms. Comparisons were done
with a 128MB heap and a 512MB heap. For all time windows, the Collie compactor
had higher MMUs than Pauseless. Collie did not go below a 70\% mutator utilization 
level whereas Pauseless ranged over the whole spectrum of values. 
This shows the aborting nature of Collie
lends itself to ensuring mutator response time, and thus decreasing latency, 
despite potentially limiting the amount of memory compacted.


\section{Field Pinning Protocol}
\label{sec:fpp}

Last, we examine concurrent compaction in GC through the Field Pinning
Protocol (FPP) designed by \"{O}sterlund and L\"{o}we~\cite{Osterlund:FPP}.
FPP describes a lock-free process for performing the relocation aspect
of concurrent compaction. The remapping phase as well as other portions
of GC are left up to the host garbage collector this
protocol is implemented within. FPP is compliant with the Java Native Interface
to allow for integration into a JVM. For purposes of testing, the FPP 
is implemented within the Garbage-First GC algorithm in the HotSpot JVM 
of OpenJDK 9~\cite{Detlefs:G1}.


\subsection{Hazard Pointers}
\label{sec:fppHazard}

The key component driving FPP is the \emph{hazard pointer} (HP)~\cite{Osterlund:FPP}. 
In FPP, all application threads contain a list of HPs.
The HPs point to objects in memory a thread is accessing, or \emph{pin} them.
When a thread finishes accessing an object, it drops the HP.
The HPs allow for asynchronous relocation of an object. So long as an object
is pinned by a mutator, it cannot be relocated as it is still in use. Once all threads have
unpinned the object, it is ready to be relocated collaboratively.
By collaboratively, we mean the last thread to drop the HP to the object
will hold the final responsibility for copying the object.
When discussing the theoretical construction of the algorithm, a granularity of pinning 
individual fields is used, thus \emph{Field} Pinning Protocol. 

While it is explained in more detail below, an example of how HPs 
work on a high-level is useful. Imagine someone brings cake to a party. Anyone 
wanting cake must make it known to others by having a plate, otherwise the 
cake is liable to be moved to the fridge. The people are effectively pinning the cake.
Once everyone has had their share of cake, it should be moved. This can
be done safely when no one has plates any longer, so no one has the cake pinned.
The last person to discard their plate will be responsible for relocating the cake.


\subsection{Tricoloring}
\label{sec:fppColoring}

A non-garbage object enters different states of the copying process 
during the relocation phase~\cite{Osterlund:FPP}. An object is
\emph{copy-white} before and after relocation. Regardless of whether the object is
currently in to or from-space, it is copy-white when in a single location with all its
references pointing to that location. An object is \emph{copy-gray} when
being relocated or awaiting relocation. Copy-gray object's have their from-space location
point to their to-space destination and their to-space destination point to a location in
memory holding the status of the object. Last, a \emph{copy-black} object has
been relocated but still requires remapping. Copy-black objects no longer require the extra
status information. FPP moves objects marked for relocation from a copy-white state to
a copy-black state without any type of checkpoint.


\subsection{Collaborative Copying and Blame}
\label{sec:fppCopy}

We now discuss in more depth how the collaborative relocation of 
non-garbage objects occurs. When a thread impedes another thread's
attempt to copy an object, because its HP prevents copying,
the impeding thread is \emph{blamed} for the 
interruption~\cite{Osterlund:FPP}. As such, it becomes responsible for ensuring 
the object is relocated. GC threads will not interrupt
mutator threads or other GC threads because they do not actually access 
the object and pin it. Thus, a GC thread cannot receive blame;
only mutator threads can "steal" responsibility for moving an object
from another thread. 

At the start of FPP relocation, GC threads will attempt to copy
objects immediately after shading all objects marked for relocation
copy-gray. At this time, blaming is disabled. That is, mutator threads
impeding initial copy attempts will not have to attempt to move the objects
themselves. 

After the first round of attempting to copy objects, the GC threads
will again try to copy the remaining copy-gray objects. If a mutator 
thread impedes the copy attempt this time, it will be blamed. 
Once the mutator is done accessing the
object and unpins it, it will attempt to perform the copy itself. If 
any other mutators have HPs to the object at that time, the copying mutator 
will be impeded. Blame will once again be passed
along to the other mutators with HPs to the object. This sequence will
occur repeatedly until a mutator tries to copy the object while no other
mutators contain HPs to the object. 

When an object is copy-gray, it has an additional copy state associated
with it. The object has an \emph{async} state if it is in from-space
and needs to be copied. It has a \emph{sync} state if there is
ongoing relocation between from and to-space and the object needs to
be protected. The protection ensures that the copy will be impeded 
should another mutator pin the object. 
Finally, an object is \emph{copied} if it was moved
successfully during the sync state. The object can be marked
copy-black once the additional status memory is removed.

The process followed by mutator threads during the relocation phase when 
accessing an object is as follows:
\begin{enumerate}
\item Pin the object by adding a HP
\item Read the color state of the object. This tells the thread whether the object
has already been copied
\item Mutate/use the object. Since the object is pinned, the thread can 
do so without worry
\item Unpin the object when no longer needed
\item If the thread was blamed due to impeding another thread's copy attempt, 
attempt to copy the object:
\begin{enumerate}
\item Scan other threads for HPs to begin transition into sync state. If HPs found,
blame all relevant threads and move along
\item Tentatively enter sync state
\item Scan once more for HPs passing blame if found and moving along
\item Now in sync state, proceed to copy the object with further
pins still impeding the copy
\end{enumerate}
\end{enumerate}

It is possible for an
object not to move because it is continually pinned. How this terminates 
depends on the host GC algorithm used. When using the Garbage-First (G1) algorithm,
this process continues until all objects are moved or another GC cycle starts.
If objects are still copy-gray when another cycle begins, they are automatically
marked for relocation again. Allowing mutators to continue passing blame works
in G1 because, like C4 and Collie, the algorithm will roll up remapping into the next
GC cycle's tracing phase. Possible alternatives include setting a max number of impediments
or setting a timer.

% So I debated whether I should've went into as much detail as I did (sync, async, copied 
% particularly). Depending on how adviser feedback goes, I may tri too scale back the 
% technical aspects here. If I do so, I will extend the cake example to elaborate
% on how new mutators impeding move/"clean-up" works.


\subsection{FPP Results Summary}
\label{sec:fppResults}

% Tested against a concurrent collector that does NOT have concurrent compaction.

As mentioned, FPP was implemented in the G1 garbage collector for testing purposes~\cite{Osterlund:FPP}. 
Appropriately, the modified G1 collector utilizing FPP for relocation is tested against the
unmodified G1 collector. This was tested in a MacBook Pro; for the 
hardware details, see~\cite{Osterlund:FPP}. We focus on the tests comparing
latency of the two garbage collectors. For other tests performed and their results, see~\cite{Osterlund:FPP}.

For latency, the h2 benchmark from DaCapo is used; for details, see~\cite{Blackburn:DaCapo}.
The benchmark was chosen due to being memory intensive and using an 8GB heap;
the memory intensiveness makes latency issues apparent.
Additionally, latency is measured using the jHiccup tool developed by Azul Systems.
Compared to its host garbage collector, G1 with FPP improved latency at all time
intervals examined. On average, latency was improved by around 50\%. That means application
pause times were about half as long. Latency was also shown to mostly be caused by 
host garbage collector activities such as tracing and remapping.


\section{Conclusions}
\label{sec:conclusions}

The concurrent compaction techniques examined are effective in reducing latency of garbage collectors.
The collectors the concurrent compaction algorithms were in were tested for latency in
different manners, so it is difficult to compare them to one another. Additionally, the
algorithms were not all designed with the same environment in mind.

As C4 and Collie were developed to be used in large server environments, we can
examine them together.
The Collie compactor needs the most additional work. As is mentioned
by the authors, it could be made generational similarly to C4~\cite{Iyengar:Collie}. 
Also, work towards a no-barrier version, discussed in theory, could be performed.
The only relevant improvement to C4 discussed by the researchers is the
final implementation tested, the version in production at the time of writing,
is not fully concurrent~\cite{Tene:C4}. It uses additional synchronization techniques between
GC phases in the sub-millisecond range. While minor, these could potentially be removed.

Both C4 and Collie require server modifications in order
to work~\cite{Tene:C4}~\cite{Iyengar:Collie}. The transactional memory 
used in Collie requires specialized hardware for implementation.
C4 needs faster allocation rates than typical Linux virtual memory provides,
which is the intended operating system. Both modifications are explained not to be difficult to do.

FPP is a more general algorithm; it is also one part of a GC algorithm
meant to be implemented into a host garbage collector. It was designed
to be easily implemented into hosts, so it does not have any special hardware or operating
system requirements. FPP is implementable in the Pauseless collector, which heavily influenced
both C4 and Collie~\cite{Osterlund:FPP}. By extension, it could likely use C4 and Collie as
its host GC algorithms. FPP works without barriers, whereas C4 and Collie use barriers, so
this might be worth looking into.

To conclude, compaction is a necessity for efficient GC with growing heaps and
increasing environmental demands. Additionally, concurrent compaction reduces the impact of compaction
on an application. For server environments, C4 is available through Azul Systems, and requires
less additional work than Collie. For barrier-free compaction in any JVM, FPP 
is easily implementable into a host garbage collector of choice. Ultimately,
the approach for compaction one wishes to use will depend on its intended environment.

%If I add in intro a note mentioning how without paralle, GC algorithms
%are hitting a wall and becoming about trade-offs. Could mention here
%that these also have some trade-offs.


\section*{Acknowledgments}
\label{sec:acknowledgments}

% To be updated as time goes on.

Thank you Elena Machkasova for the great advice and feedback.
Thank you Jeremy Eberhardt for briefing me on the senior seminar process early on.


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% sample_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{sample_paper}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\end{document}

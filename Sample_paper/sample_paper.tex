% This is a sample document using the University of Minnesota, Morris, Computer Science
% Senior Seminar modification of the ACM sig-alternate style. Much of this content is taken
% directly from the ACM sample document illustrating the use of the sig-alternate class. Certain
% parts that we never use have been removed to simplify the example, and a few additional
% components have been added.

% See https://github.com/UMM-CSci/Senior_seminar_templates for more info and to make
% suggestions and corrections.

\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorinlistoftodos]{todonotes}

%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR AS NEEDED
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2015}{Morris, MN}

\title{Parallel Processing in Garbage Collection: An Examination of Concurrent Compaction Techniques}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Jacob P. Opdahl\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{opdah023@morris.umn.edu}
}

\maketitle
\begin{abstract}
This paper provides an overview of garbage collection (GC) and parallel
processing as well as how parallel processing applies to GC.
With that knowledge as our foundation, we will examine in detail various
algorithms that perform compaction of fragmented memory during garbage 
collection concurrently to the application running.
% The current paper format *only* allows inline comments using the todo
% macro. That's kind of a bummer, and it would be neat if someone figured
% out how to change the acmconf style to allow this. I suspect it isn't *hard*
% but there are quite a few details that have to be sorted out in synchrony.
\todo[inline]{Needs more work}
\end{abstract}

\keywords{Garbage Collection, GC, Concurrency, Compaction, Continuously Concurrent Compacting Collector (C4), Collie, Field Pinning Protocol (FPP)}

\section{Introduction}
\label{sec:introduction}

To be done at a later date...


\section{Background}
\label{sec:background}

\todo[inline]{Just threw stuff from outline in this section for now.}

This is where I explain terminology and aspects of GC and parallel 
computing that are necessary to understand my paper (If there is 
enough information in each subsection, I should maybe forego the 
background and just make them all sections)

\subsection{Garbage Collection}
\label{sec:garbageCollection}

References and the heap (if not done in the introduction)

General process flow GC algorithms tend to follow

Specific GC algorithms/techniques my researched papers will 
refer to and common techniques needed to understand my paper 
(Pauseless, tracing/marking, more)

Start introducing some terminology relevant to single processor 
garbage collectors such as: stop-the-world, fragmentation, compaction, 
tracing, reference remapping, etc.

Explain the three typical aspects of compaction 
(relocation/copying, remapping, and reclamation: 
reclamation is often just done through the other two)

\subsection{Parallel Processing}
\label{sec:parallelProcessing}

Threads: the virtual form of a processor (might need to 
explain virtualization or abstraction)

Issues experienced in parallel computing and reasons why it 
is difficult to perform effectively like: deadlock, race conditions, 
etc. (Real brief, but I feel the audience needs to have some idea of 
why progress in this area doesn't happen overnight. It also seems 
necessary for explaining barriers)

Typical ways of mitigating challenges experienced in parallel 
computing (synchronization, barriers/locks)

\todo[inline]{Decided a portion I wrote for my current section, Collie,
should be included in the general background. Trowing what I wrote here
for now. Will be rewritten later.}
A \emph{global safepoint} is requested by a thread and is a moment when all 
threads are paused such that operations can be performed by the requesting thread without having to worry 
about references in the application changing. As a global safepoint requires pausing application
threads, this breaks concurrency.
Note that a safepoint differs from a barrier in GC. In a safepoint,
all threads are allowed to reach a certain point then their execution is simply paused.
A barrier works by telling threads how to behave if multiple try to access the same
memory. Thus, using a global safepoint does not break the goal of barrier-free compaction
~\cite{Humble:2015}.

\subsection{Parallel Processing as it Applies to Garbage Collection}
\label{sec:parallelProcessingGarbageCollection}

Bring audience's attention back to the original focus introduced 
of wanting to use parallel computing to improve GC

Introduce new terminology for GC that depends on parallel processing 
in order to show some more specific ways in which parallel processing 
can be used to improve GC (mutator threads, parallelism, concurrency, etc.)

Describe the focus: Concurrent Compaction (If this has enough information, 
it could be moved out of being a component in a subsection)


\section{The C4 Collector}
\label{sec:c4}

To be done at a later date...


\section{The Collie Collector}
\label{sec:collie}

We now look at the concurrent compaction technique used within the 
Collie garbage collector described by Iynegar et al.~\cite{Iyengar:Collie}. 
Like C4, the Collie is a fully concurrent compacting collector. It 
uses a tracing algorithm based on the one implemented in C4 for 
marking which objects are garbage. Likewise, the Collie uses a read
barrier similar to the Loaded Value Barrier (LVB) in C4 for 
compaction.


\subsection{Transactional Memory}
\label{sec:collieTM}
The Collie's compaction algorithm sets itself apart due to its use 
of a \emph{transactional memory} (TM) system as a concurrency control 
alternative to barriers~\cite{Iyengar:Collie}. TM systems allow
sections of code to function 
analogously to \emph{transactions} from database systems, 
which are a series of operations performed as one unit where 
they occur in an all-or-none manner~\cite{wiki:atomicity}.

For example, consider updating the inventory of a store; this may involve updating
the price, quantity and distributor for various items. 
If a person was updating information regarding an item, they would 
want all three attributes of the item to be updated or none at all. Having
only a subset of the attributes updated could cause confusion.

TM systems allow a series
of operations that modify memory to be placed in
a \emph{transactional procedure}, much like a database transaction.
The TM system then monitors the access of concurrent threads to \emph{transactional variables}:
memory that is modified by a transactional procedure.
Concurrent threads will continue to operate in parallel until they try to modify
the same transactional variable. At this time, behavior can be specified as to how 
the conflict should play out, but the general pattern would be for one transaction
to be aborted and the other allowed to play out.
When a transaction is completed, its changes are \emph{committed}; any changes 
made to memory by the transaction are finalized~\cite{wiki:transactional-memory}.


\subsection{Object Transplantation}
\label{sec:collieTransplantation}
%I'll probably want to change this subsection title.

% Two possible changes to come here. If C4 also does reclamation the "easy way"
% as described by FPP, then mentioning it in background and elsewhere can probably
% be simplified to a simple note of that being how it's handled by all the algorithms
% I discuss. Also, Might not need the refresher on relocation and remapping if talked
% about recently before.
With the use of a TM system for synchronizing concurrent compaction,
new terminology is introduced for understanding the Collie 
compactor~\cite{Iyengar:Collie}. As discussed, compaction of
memory requires relocation of objects and remapping of references to
the objects; the Collie does reclamation by labeling the from-space as freed.
An object \emph{transplantation} consists of both the relocation and 
remapping of an object. A transplantation has not been completed until
the object's contents have been moved and all required references have been
updated. All relocating collectors, and by extension all
compacting collectors, transplant objects.

Each object in an application's memory has a \emph{referrer set}. This is the precise set 
of all references pointing to the object. 
An object has a \emph{transplantation state} consisting of the object's contents 
and the object's referrer set. This definition builds on the general requirements
for completing an object transplantation. These
requirements include: all copies of an object's contents should remain consistent
until transplantation is completed and after transplantation, there cannot be any
references that point to the object's from-space location in its referrer set.

\todo[inline]{Might need to add more background. Wait to see how discussing the algorithm goes. Add: mirrored to-space, zero-copy translation.}

\subsection{The Collie Protocol}
\label{sec:collieAlgorithm}

While working to use a TM system to support concurrent thread 
synchronization, the first theoretical, 
but not practical, barrier-free compacting algorithm is 
conceived~\cite{Iyengar:Collie}. From this,
they introduce a wait-free read barrier into the algorithm that has a bounded,
constant triggering time.
This is done to make the compaction algorithm practical and concurrent
so it can be used in the overall Collie GC algorithm.
We will discuss both the theoretical compaction algorithm as well
as the modified concurrent implementation here.

\subsubsection{Theoretical, Barrier-free Compaction Algorithm}
\label{sec:collieAlgorithmNoBarriers}

The compaction algorithm uses TM semantics to complete an object's
transplantation. The operations for transplantation are stored as a
transactional procedure. These operations include: the compactor 
starting a memory transaction, it "protecting" the referrer set, 
the object being copied to its new location and the references in the 
referrer set being updated to point to the new location of the object.
After the final steps modifying the transplantation state of the object,
the transaction is committed.

By the compactor "protecting" the referrer set, we mean the algorithm
writes to each of its references so they cannot be read from. 
Reads from the referrer set could expand, and thus modify, it. This could result
in references to the object being created that the transactional procedure
was not aware of when starting, so they are not updated to point to 
the new object location when it is finishing. Thus, for the transaction to
ensure all references are up-to-date upon completion, the referrer set needs
to be protected.

This brings us to discussing why this compaction algorithm is not concurrent. 
If the aforementioned transactional procedure is not
modified, there will be a gap between the transaction beginning and
the entire referrer set being written to and protected. This gap allows 
the referrer set to expand without the transaction knowing about it
as discussed.

To prevent this, the transaction must be started inside a global safepoint.
Within the global safepoint, the precise referrer
set is constructed, the transaction is started, and the referrer set is protected.
After this, the safepoint ends and other threads are allowed to continue concurrently
while TM semantics will ensure the relocation and remapping portions of compaction
are safe.

While it does not require traditional barriers, the cost of not using them effectively
requires stop-the-world phases. Global safepoints would need to be enacted for every 
object that is relocated. Thus, the number of stop-the-world pauses that would occur
during this barrier-free compaction is what makes it impractical.

\todo[inline]{Need references. Again, I used mostly random articles...}
\todo[inline]{Do you feel I need to explicitly state what would cause the transactional
memory to kick in and handle concurrency issues? I think I covered it enough with the
additional background.}

%Talk more about operations that would cause the transaction to be aborted and give examples?

\subsubsection{Implemented Compaction Algorithm}
\label{sec:collieAlgorithmImplementation}

Now, we examine the concurrent compaction algorithm that builds on the idea of
using a TM system for individual object transplantation, but foregoes the goal 
of doing so in a barrier-free manner. Like the compaction algorithm in the C4 
collector, this algorithm compacts at page granularity and uses a quick release 
technique to quickly free physical memory backing the from-space.

\subsection{Summary of Results}
\label{sec:collieResults}
%Again, another name for this subsection could be good.

More things


\section{Field Pinning Protocol}
\label{sec:fpp}

To be done at a later date...


\section{Conclusions}
\label{sec:conclusions}

To be done at a later date...


\section*{Acknowledgments}
\label{sec:acknowledgments}

To be done at a later date...


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% sample_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{sample_paper}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\end{document}
